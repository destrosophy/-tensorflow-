```diff
1、机器学习简介
-  监督学习
+  条件：预先知道输入的样例属于哪一类
+  数据集：包含有标签的数据
+  大部分监督学习的共同特点： 定义“损失函数”和“代价函数”，对训练集进行处理时使其最小化
+  适用场景：分类场景、学习数值型预测函数（回归） ——这些算法可视为一套描述分类器和预测器的规则，其中包括决策树、决策法则、神经网络、贝叶斯网络
-  无监督学习
+  条件：在训练过程中提供给系统的输入时没有标签的
+  适用场景：处理聚类问题，即给定一系列对象，我们希望理解并展示他们之间的关系
+  一种标准的做法：唯美两个对象定义一种相似度，据此找出簇的划分，使得簇内对象相似度较大，簇间对象相似度相对较小
-  强化学习
+  强调：利用系统与其环境之间的交互进行学习，通过强化学习从环境中获取反馈动态调整其参数，调参的结果又进一步作为反馈指导决策
+  举例：用前面棋步的结果作为改进性能的国际象棋程序
+  覆盖领域：遗传算法、神经网络、心理学和控制工程等多个领域


2、深度学习
+  与机器学习的关系：机器学习是一种实现人工智能的方法，深度学习是一种实现机器学习的技术
+  特点：建立一个多层学习模型，深层级将浅层级的输出作为输入，将数据层层转化，越来越抽象
+  举例：人脸识别问题中的层级建立过程
+           第一层：系统开始识别明暗像素
+           第二层：系统识别边缘和形状
+           第三层：系统学习到更为复杂的形状和物体
+           第四层：系统学习人脸由哪些物体定义

3、人工神经网
-  组成：
+      一个或多个入连接，用于从其他神经元接收数字信号，每个连接都被赋予一个权重，用于信号加权
+      一个或多个输出连接，用于向其他神经元发出信号
+      一个激活函数，该函数从其他神经元接收输入信号并对其进行适当加权，结合该神经元的激活阈值决定输出参数的数值  输入->计算加权和->激活函数->输出
-  激活函数    https://baike.baidu.com/item/激活函数/2520792?fr=aladdin
+  为什么引入激活函数：
+  引入激活函数是为了增加神经网络模型的非线性。没有激活函数的每层都相当于矩阵相乘。就算你叠加了若干层之后，无非还是个矩阵相乘罢了。
+  常见的激活函数：
+  阶跃函数：函数会定义一个固定阈值x（如x=10），当输入的加权和等于、大于或小于该阈值时，函数将返回0或1
+  线性组合：用输入值的加权和减去一个默认值，最终会得到一个二进制值，但一般将其表示为正类（+b）和负类（-b）输出
+  sigmoid函数：生成一个S形sigmoid曲线


4、人工神经网络的学习方式
+  神经网络的学习过程是对权重的迭代优化，因此属于监督学习的范畴。
-  反向传播算法
+  基本步骤：
+         （1）以随机权重初始化网络
+         （2）对于每个训练样本，重复以下过程
+               前向传播:计算网络产生的总误差，即网络输出与正确输出的差值
+               反向传播：从输出层到输入层，反向遍历所有层
+         （3）在反向遍历的过程中根据上一层的误差和对应的权值，逐层计算网络内部各层误差，从而总是将输出层向隐藏层反复传递，直到传播到输入层
+         （4）根据各层误差调整各层的权重，以最小化误差函数。
-  权重优化->梯度下降法
+  基本步骤：
+         （1）随机选择参数初始值
+         （2）对模型中的每个参数，计算误差函数的梯度G
+         （3）调整模型参数，使其向误差减小的方向移动
+         （4）重复步骤（2）直到G的值趋近于0
-  随机梯度下降法：
+  训练集越大，算法对权值的升级越慢，收敛到全局最优解的时间也越长，所以我们提出随机梯度下降法，我们在一次迭代中只用一个训练样例升级一个参数，每处理一个训练样本，权值都能得到一次更新，但会走一些弯路


5、神经网络架构：
-  组成：
+   节点的连接方式、网络的层数和每层神经元的数量
-  类型：   https://www.asimovinstitute.org/neural-network-zoo/
+  多层感知器
    特点： 每个神经元与下一层所有神经元都相连，同一层的神经元都不相连，不相邻的层中的神经元之间没有联系，网络的层数和每层的神经元的数量取决于需要解决的问题
+  DNN
+  卷积神经网络CNN
+  受限玻尔兹曼机RBM
    
    
